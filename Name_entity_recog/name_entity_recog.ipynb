{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"data/ner_dataset.csv\",encoding = \"ISO-8859-1\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path,\"r\") as file:\n",
    "        data=[ line.strip() for line in file.readlines()] \n",
    "    return data\n",
    "train_sentence=load_data('data/large/train/sentences.txt')\n",
    "train_labels=load_data('data/large/train/labels.txt')\n",
    "\n",
    "val_sentence=load_data('data/large/val/sentences.txt')\n",
    "val_labels=load_data('data/large/val/labels.txt')\n",
    "test_sentence=load_data('data/large/test/sentences.txt')\n",
    "test_labels=load_data('data/large/test/labels.txt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(sentences):\n",
    "    vocab={}\n",
    "    vocab[\"<unk>\"]=0\n",
    "    i=1\n",
    "    for sentence in sentences:\n",
    "        sentence=sentence.strip().split()\n",
    "        for word in sentence:\n",
    "            if word not in vocab.keys():\n",
    "                vocab[word]=i\n",
    "                i+=1\n",
    "    return vocab\n",
    "\n",
    "vocab=create_vocab(train_sentence)\n",
    "label_vocab=create_vocab(train_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_sentence(vocab,sentences):\n",
    "    vectorized_sentences=[]\n",
    "    max_len=0\n",
    "    for i,sentence in enumerate(sentences):\n",
    "        sentence=sentence.strip().split()\n",
    "        max_len=np.maximum(max_len,len(sentence))\n",
    "        vectorized=[vocab.get(word,0) for word in sentence]\n",
    "        vectorized_sentences.append(torch.tensor(vectorized))\n",
    "    return vectorized_sentences,max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,max_len1=vectorized_sentence(vocab,train_sentence)\n",
    "test_data,max_len2=vectorized_sentence(vocab,test_sentence)\n",
    "train_label_data,_=vectorized_sentence(label_vocab,train_labels)\n",
    "test_label_data,_=vectorized_sentence(label_vocab,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=0\n",
    "max_len=np.maximum(max_len,max_len1)\n",
    "max_len=np.maximum(max_len,max_len2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "len_train=len(train_data)\n",
    "data_for_padding=train_data+test_data\n",
    "data=pad_sequence(data_for_padding,padding_value=0.0,batch_first=True)\n",
    "X_train=data[:len_train]\n",
    "X_test=data[len_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_padding2=train_label_data+test_label_data\n",
    "data1=pad_sequence(data_for_padding2,padding_value=0,batch_first=True)\n",
    "y_train=data1[:len_train]\n",
    "y_test=data1[len_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=torch.utils.data.TensorDataset(X_train,y_train)\n",
    "test_dataset=torch.utils.data.TensorDataset(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=64,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=64\n",
    "hidden_size=128\n",
    "\n",
    "\n",
    "class Ner_model(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,output_size,hidden_size):\n",
    "        super(Ner_model,self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab_size,embedding_size,padding_idx=0)\n",
    "        self.rnn=nn.LSTM(embedding_size,hidden_size,num_layers=2,batch_first=True)\n",
    "        self.out=nn.Linear(hidden_size,output_size)\n",
    "    def forward(self,x):\n",
    "        x=self.embedding(x)\n",
    "        x,_=self.rnn(x)\n",
    "        x=self.out(x)\n",
    "        return x.permute(0,2,1)\n",
    "model=Ner_model(len(vocab),embedding_size,output_size=len(label_vocab),hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from engine import train\n",
    "device=\"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 104, 29846])\n",
      "torch.Size([64, 104])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10.2502, grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=train(model,train_loader,test_loader,optimizer,loss,5,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lqd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
